{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graded Assignment 1 : MNIST classifier using numpy and python without CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuhbSLIK5D84O/N/8Mm0nK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrnTEK/Deep-Learning/blob/master/Graded_Assignment_1_MNIST_classifier_using_numpy_and_python_without_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWMG5ScdxtuC",
        "colab_type": "text"
      },
      "source": [
        "#Creating MNIST Classifier using Numpy\n",
        "###Goal is to use plain feed forward NNs without keras NN library but just numpy  (you can use keras only for image augmentation and getting training set and nothing else)\n",
        "Following are the tasks that needs to be accomplished by the code:\n",
        "\n",
        "1. The code should normalize the input as discussed in the class before training (scaling the input) \n",
        "2. The code should do mini batch gradient descent along with appropriate learning\n",
        "3. The code should do dropout - try various dropout rates and pick the one which works well. (need not be same for all layers)\n",
        "4. The code should initialize the random weights of network properly\n",
        "5. The code should do basic image augmentations to supplement the training data (not testing data) using keras libraries\n",
        "6. The code should use  3 or more layers for training (not 2 as in example ) - you have to tune and pick number of neurons in your layer and number of layers\n",
        "7. The code will continue to use relu activation layer in right places like python code\n",
        "8. The code should use appropriate learning rate (try out few to find out which one works) - you can use adaptive learning rates like different learning rates per epoch or per mini batch\n",
        "9. The code should provide appropriate metrics, visualization,  testing and training accuracy etc.,. and plot the results and confusion matrix  (this is important)\n",
        "10. The code should display top common errors images identified incorrectly\n",
        "11. Extra points if you hit 99% test accuracy with these changes (very challenging given you are not using CNNs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJfKgu_Hzfo7",
        "colab_type": "text"
      },
      "source": [
        "##Importing the Libraries required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gurNbLv1xnVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS3GlqID5oIT",
        "colab_type": "text"
      },
      "source": [
        "####Importing MNIST Files from Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzHS0vK15lkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "131e34c1-c3b5-44ca-f97b-996e81fa041c"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#https://drive.google.com/open?id=1Hcx5VtkGIjH9gU2O7_RLvKhBPgPgqHnX\n",
        "#https://drive.google.com/open?id=16StDwyeRpgtWjmGK-k04iN8iHcSUhzhe\n",
        "file_id1 = '1Hcx5VtkGIjH9gU2O7_RLvKhBPgPgqHnX'\n",
        "downloaded = drive.CreateFile({'id': file_id1})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "downloaded.GetContentFile('mnist_train.csv')  \n",
        "mnist_train = pd.read_csv('mnist_train.csv')\n",
        "mnist_train.to_csv('mnist_train.csv')\n",
        "\n",
        "\n",
        "file_id2 = '16StDwyeRpgtWjmGK-k04iN8iHcSUhzhe'\n",
        "downloaded = drive.CreateFile({'id': file_id2})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "downloaded.GetContentFile('mnist_test.csv')  \n",
        "mnist_test = pd.read_csv('mnist_test.csv')\n",
        "mnist_test.to_csv('mnist_test.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkIv0LH44Ple",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#redundant code to be deleted\n",
        "#Loading the Mnist dataset from Keras dataset\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
        "#mnist = input_data.read_data_sets(\"MNIST_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfB5pVqR9y4X",
        "colab_type": "text"
      },
      "source": [
        "###Converting images to numpy array for easy calculation\n",
        "\n",
        "Also checking the shape and dimentions in the numpy array defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox_IcA3VbxAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3277b43d-c827-4f3c-fb04-c88659e5b492"
      },
      "source": [
        "# default pixel width and length numbers\n",
        "image_size = 28 \n",
        "#Number of output labels is 10 which is 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
        "number_output_label = 10\n",
        "\n",
        "image_pixels = image_size * image_size\n",
        "\n",
        "#Converting dataframe to numpy array\n",
        "train_data = mnist_train.to_numpy()\n",
        "test_data = mnist_test.to_numpy() \n",
        "\n",
        "test_data[test_data==255]\n",
        "train_data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59999, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbUuNk-7543U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#redundant code to be deleted. Use this for Keras dataset import directly\n",
        "#Not use if internet is slow as it can take lot of time\n",
        "\n",
        "#x_train = np.vstack([img.reshape(-1,) for img in mnist.train.images])\n",
        "#y_train = mnist.train.labels\n",
        "\n",
        "#x_test = np.vstack([img.reshape(-1,) for img in mnist.test.images])\n",
        "#y_test = mnist.test.labels\n",
        "#x_train.shape\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eO9zQe4Blr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Redundant code to be deleted. Used this for storing the dataset to local RAM after importing\n",
        "#Can be used if using TPU but this slows down in GPU later\n",
        "\n",
        "#x_train = np.float32(mnist['x_train'][:])\n",
        "#y_train = np.int32(np.array(MNIST_data['y_train'][:, 0])).reshape(-1, 1)\n",
        "#x_test  = np.float32(MNIST_data['x_test'][:])\n",
        "#y_test  = np.int32(np.array(MNIST_data['y_test'][:, 0])).reshape(-1, 1)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2n3pS_V_93U",
        "colab_type": "text"
      },
      "source": [
        "Now we have a 2 dimentional numpy array with 60000 rows with 784 (28 X 28) features of data in other two dimentions. We can now carry out the normalization of the data.\n",
        "\n",
        "There is also an alternative method as well that we can follow:\n",
        "\n",
        "The difference is that this will yield 3-dimentional array which needs to be reshaped into 2-D\n",
        "\n",
        "  * from tensorflow.keras.datasets import mnist:\n",
        "  * (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  * Converting training data to Numpy array\n",
        "  * mnist_train = np.array(x_train)\n",
        "  * mnist_trtarget = np.array(y_train)\n",
        "  * Coverting test data to Numpy array\n",
        "  * mnist_test = np.array(x_test)\n",
        "  * mnist_tetarget = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_45pvZ2NpiU",
        "colab_type": "text"
      },
      "source": [
        "###Prininting first record to check the values and range of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUNrWNpWASuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73308384-ac73-4c2f-fe50-342d00ca46b3"
      },
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(width=100, compact = True)\n",
        "pp.pprint(train_data[48000])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([  7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0, 170, 226,  57,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "       226, 114,   0,   0,   0,  57, 198, 255, 255,  86,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0, 141, 255, 255, 170, 255, 255, 255, 255, 255, 255,  29,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0, 226, 255, 255, 255, 255, 255, 255, 255, 255,  86,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0, 170, 255, 255, 198, 170,  86, 114, 255, 255,\n",
            "       226,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0, 226, 255, 255, 170,   0,   0,   0, 170,\n",
            "       255, 255,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,  86, 255, 255, 170,   0,   0,   0,\n",
            "         0, 255, 255, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,  29, 170, 170,  29,   0,\n",
            "         0,   0, 141, 255, 255, 114,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0, 170, 255, 255,  57,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,  29, 255, 255, 226,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0, 141, 255, 255,  86,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0, 226, 255, 255,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 255, 255,\n",
            "       114,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198,\n",
            "       255, 255,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        57, 255, 255, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0, 141, 255, 255,  86,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0, 114, 226, 255, 226,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,  29, 255, 255, 255,  86,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0, 141, 255, 255, 170,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,  86, 226, 226,  57,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P-tLGSZN_h3",
        "colab_type": "text"
      },
      "source": [
        "###One Hot Encoding and data Transforming\n",
        "\n",
        "As we can see from the above values that there are many zero values for pixels which are not activated this is something we need to avoid since weights dont update well for zero values also the value in array range from 0 to 255. we will divide the array by 255 and will add 0.01 to the result to ensure that we have no zero values and range can be between 0.01 to 0.99"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_YcQ_CltLKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fac = 0.99 / 255\n",
        "X_train = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
        "X_test = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
        "\n",
        "#Separating training and test labels\n",
        "Y_train = np.asfarray(train_data[:, :1])\n",
        "Y_test = np.asfarray(test_data[:, :1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl-ko7UtYB1G",
        "colab_type": "text"
      },
      "source": [
        "###Encoding Output label as well with one hot encoding\n",
        "\n",
        "Encoding Y training and Y test labels for entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-SaspP61l44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a64007fd-0df8-455a-c83a-3583ef0e8315"
      },
      "source": [
        "# one-hot encoding\n",
        "import numpy as np\n",
        "\n",
        "lr = np.arange(10)\n",
        "\n",
        "for label in range(10):\n",
        "    one_hot = (lr==label).astype(np.int)\n",
        "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
            "label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
            "label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
            "label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
            "label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
            "label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
            "label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
            "label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
            "label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
            "label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgWQbKHOXmxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = np.arange(number_output_label)\n",
        "\n",
        "# transform labels into one hot representation\n",
        "train_labels_one_hot = (lr==Y_train).astype(np.float)\n",
        "test_labels_one_hot = (lr==Y_test).astype(np.float)\n",
        "\n",
        "# we don't want zeroes and ones in the labels neither:\n",
        "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
        "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
        "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
        "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RFxr6o5TtnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Redundant Code To be deleted. Used it for training and test shuffle and split\n",
        "#Multiple errors on data type conversion.\n",
        "#Use above cell for encoding and transformation\n",
        "\n",
        "#digits = 10\n",
        "#examples = mnistar_train.shape[0]\n",
        "#mnistar_train = mnistar_train.reshape(1, examples)\n",
        "#Y_train = np.eye(digits)[mnistar_train.astype('int32')]\n",
        "#Y_train = Y_train.T.reshape(digits, examples)\n",
        "\n",
        "#digits = 10\n",
        "#examples = mnistar_test.shape[0]\n",
        "#mnistar_test = mnistar_test.reshape(1, examples)\n",
        "#Y_test = np.eye(digits)[mnistar_test.astype('int32')]\n",
        "#Y_test = Y_test.T.reshape(digits, examples)\n",
        "\n",
        "# number of training set\n",
        "#m = 55000\n",
        "#m_test = X.shape[0] - m\n",
        "#X_train, X_test = X[:m].T, X[m:].T\n",
        "#Y_train, Y_test = Y_new[:, :m], Y_new[:, m:]\n",
        "\n",
        "# shuffle training set\n",
        "#shuffle_index = np.random.permutation(m)\n",
        "#X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n",
        "\n",
        "#X_transpose = X_train[:].T #redundant code for checking the data orientation\n",
        "#X_transpose.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geHtew4nalXX",
        "colab_type": "text"
      },
      "source": [
        "###Displaying the output for training data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwMkG-e3YrS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5d4e8e0-afbe-4b90-cb57-dff28cd9f4f8"
      },
      "source": [
        "for i in range(4):\n",
        "    img = X_train[i].reshape((28,28))\n",
        "    plt.imshow(img, cmap=\"Greys\")\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8PJdJc1jCDmVwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZiATIHN5e3c",
        "colab_type": "text"
      },
      "source": [
        "###Saving the data in a pickle file for quick access and caching of data in Local GPU RAM in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVEi02iSY8bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "#This is a Binary write (Check 'bw')\n",
        "with open(\"pickled_mnist.pkl\", \"bw\") as fh:\n",
        "    data = (X_train, \n",
        "            X_test, \n",
        "            Y_train,\n",
        "            Y_test,\n",
        "            train_labels_one_hot,\n",
        "            test_labels_one_hot)\n",
        "    pickle.dump(data, fh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8huDW-UF1hSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"pickled_mnist.pkl\", \"br\") as fh:\n",
        "    data = pickle.load(fh)\n",
        "\n",
        "X_train = data[0]\n",
        "X_test = data[1]\n",
        "Y_train = data[2]\n",
        "Y_test = data[3]\n",
        "train_labels_one_hot = data[4]\n",
        "test_labels_one_hot = data[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF7ddh-77XV5",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Classifier Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AY4_y057qxF",
        "colab_type": "text"
      },
      "source": [
        "####Creating the Sigmoid & relu function class as defined in slides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLI3fTFT7Qtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@np.vectorize\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    sigmoid activation function.\n",
        "\n",
        "    inputs: z\n",
        "    outputs: sigmoid(z)\n",
        "    \"\"\"\n",
        "    s = 1. / (1. + np.exp(-z))\n",
        "    return s\n",
        "activation_function = sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLtLZp-hxAG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@np.vectorize\n",
        "def relu(x):\n",
        "  return x * (x > 0)\n",
        "\n",
        "def dReLU(x):\n",
        "  return 1. * (x > 0)\n",
        "#activation_function = relu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntnRLYD57opa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.special import expit as activation_function\n",
        "from scipy.stats import truncnorm\n",
        "\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm((low - mean) / sd,\n",
        "                     (upp - mean) / sd, \n",
        "                     loc=mean, \n",
        "                     scale=sd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayFdA_5e7835",
        "colab_type": "text"
      },
      "source": [
        "####Simple Neural network creation with multiple Hidden layers and Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2BxI6HP764M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        " \n",
        "    def __init__(self, \n",
        "                 no_of_in_nodes, \n",
        "                 no_of_out_nodes, \n",
        "                 no_of_hidden_nodes,\n",
        "                 learning_rate,\n",
        "                 bias=None\n",
        "                ):  \n",
        "\n",
        "        self.no_of_in_nodes = no_of_in_nodes\n",
        "        self.no_of_out_nodes = no_of_out_nodes\n",
        "        \n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
        "            \n",
        "        self.learning_rate = learning_rate \n",
        "        self.bias = bias\n",
        "        self.create_weight_matrices()\n",
        "    \n",
        "        \n",
        "    \n",
        "    def create_weight_matrices(self):\n",
        "        \"\"\" \n",
        "        A method to initialize the weight matrices \n",
        "        of the neural network with optional \n",
        "        bias nodes\"\"\"\n",
        "        \n",
        "        bias_node = 1 if self.bias else 0\n",
        "        \n",
        "        rad = 1 / np.sqrt(self.no_of_in_nodes + bias_node)\n",
        "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
        "        \n",
        "        self.wih = X.rvs((self.no_of_hidden_nodes, self.no_of_in_nodes + bias_node))\n",
        "\n",
        "        rad = 1 / np.sqrt(self.no_of_hidden_nodes + bias_node)\n",
        "        X = truncated_normal(mean=0, \n",
        "                             sd=1, \n",
        "                             low=-rad, \n",
        "                             upp=rad)\n",
        "        self.who = X.rvs((self.no_of_out_nodes, \n",
        "                          self.no_of_hidden_nodes + bias_node))\n",
        "        \n",
        " \n",
        "    def train_single(self, input_vector, target_vector):\n",
        "        \"\"\"\n",
        "        input_vector and target_vector can be tuple, \n",
        "        list or ndarray\n",
        "        \"\"\"\n",
        "\n",
        "        bias_node = 1 if self.bias else 0\n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the inpuy_vector\n",
        "            input_vector = np.concatenate( (input_vector, \n",
        "                                            [self.bias]) )\n",
        "        \n",
        "        output_vectors = []\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\n",
        "\n",
        "        \n",
        "        output_vector1 = np.dot(self.wih, input_vector)\n",
        "        output_hidden = activation_function(output_vector1)\n",
        "        \n",
        "        if self.bias:\n",
        "            output_hidden = np.concatenate((output_hidden, [[self.bias]]) )\n",
        "\n",
        "        \n",
        "        output_vector2 = np.dot(self.who, output_hidden)\n",
        "        output_network = activation_function(output_vector2)\n",
        "        \n",
        "        output_errors = target_vector - output_network\n",
        "        # update the weights:\n",
        "        tmp = output_errors * output_network * (1.0 - output_network)          \n",
        "        tmp = self.learning_rate  * np.dot(tmp, output_hidden.T) \n",
        "        self.who += tmp\n",
        "\n",
        "        \n",
        "        # calculate hidden errors:\n",
        "        hidden_errors = np.dot(self.who.T, output_errors)\n",
        "        # update the weights:\n",
        "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
        "        if self.bias:\n",
        "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
        "        else:\n",
        "            x = np.dot(tmp, input_vector.T)\n",
        "        self.wih += self.learning_rate * x\n",
        "        \n",
        "\n",
        "    def train(self, data_array, \n",
        "              labels_one_hot_array,\n",
        "              epochs=1,\n",
        "              intermediate_results=False):\n",
        "        intermediate_weights = []\n",
        "        for epoch in range(epochs):  \n",
        "            for i in range(len(data_array)):\n",
        "                self.train_single(data_array[i], \n",
        "                                  labels_one_hot_array[i])\n",
        "            if intermediate_results:\n",
        "                intermediate_weights.append((self.wih.copy(), \n",
        "                                             self.who.copy()))\n",
        "        return intermediate_weights      \n",
        "        \n",
        "\n",
        "        \n",
        "    \n",
        "    def run(self, input_vector):\n",
        "        # input_vector is tuple, list or ndarray\n",
        "        \n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the input_vector\n",
        "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "\n",
        "        output_vector = np.dot(self.wih, input_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        \n",
        "        if self.bias:\n",
        "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
        "            \n",
        "\n",
        "        output_vector = np.dot(self.who, output_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "    \n",
        "        return output_vector\n",
        "    \n",
        "    \n",
        "    def evaluate(self, data, labels):\n",
        "        corrects, wrongs = 0, 0\n",
        "        for i in range(len(data)):\n",
        "            res = self.run(data[i])\n",
        "            res_max = res.argmax()\n",
        "            if res_max == labels[i]:\n",
        "                corrects += 1\n",
        "            else:\n",
        "                wrongs += 1\n",
        "        return corrects, wrongs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o58mbSYL8ffz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "71e3863a-bcfa-48c8-c561-6f80320fb909"
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "feed_forward = NeuralNetwork(no_of_in_nodes=image_pixels, \n",
        "                        no_of_out_nodes=10, \n",
        "                        no_of_hidden_nodes=100,\n",
        "                        learning_rate=0.1,\n",
        "                        bias=None)\n",
        "\n",
        "weights = feed_forward.train(X_train, \n",
        "                        train_labels_one_hot, \n",
        "                        epochs=epochs, \n",
        "                        intermediate_results=True) \n",
        "for epoch in range(epochs):  \n",
        "    print(\"epoch: \", epoch)\n",
        "    feed_forward.wih = weights[epoch][0]\n",
        "    feed_forward.who = weights[epoch][1]\n",
        "    corrects, wrongs = feed_forward.evaluate(X_train, Y_train)\n",
        "    print(\"accuracy train: \", corrects / ( corrects + wrongs))                   \n",
        "    corrects, wrongs = feed_forward.evaluate(X_test, Y_test)\n",
        "    print(\"accuracy test: \", corrects / ( corrects + wrongs)) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "accuracy train:  0.9466991116518608\n",
            "accuracy test:  0.9477947794779478\n",
            "epoch:  1\n",
            "accuracy train:  0.96021600360006\n",
            "accuracy test:  0.956995699569957\n",
            "epoch:  2\n",
            "accuracy train:  0.9645327422123702\n",
            "accuracy test:  0.956995699569957\n",
            "epoch:  3\n",
            "accuracy train:  0.9667161119351989\n",
            "accuracy test:  0.9567956795679567\n",
            "epoch:  4\n",
            "accuracy train:  0.9648827480458008\n",
            "accuracy test:  0.9554955495549555\n",
            "epoch:  5\n",
            "accuracy train:  0.9687994799913332\n",
            "accuracy test:  0.9556955695569557\n",
            "epoch:  6\n",
            "accuracy train:  0.9707995133252221\n",
            "accuracy test:  0.9586958695869587\n",
            "epoch:  7\n",
            "accuracy train:  0.9728662144369072\n",
            "accuracy test:  0.9613961396139614\n",
            "epoch:  8\n",
            "accuracy train:  0.9713661894364906\n",
            "accuracy test:  0.9602960296029603\n",
            "epoch:  9\n",
            "accuracy train:  0.9733328888814814\n",
            "accuracy test:  0.9591959195919592\n",
            "epoch:  10\n",
            "accuracy train:  0.9723995399923332\n",
            "accuracy test:  0.9583958395839584\n",
            "epoch:  11\n",
            "accuracy train:  0.9700495008250137\n",
            "accuracy test:  0.9571957195719571\n",
            "epoch:  12\n",
            "accuracy train:  0.9738495641594026\n",
            "accuracy test:  0.9576957695769577\n",
            "epoch:  13\n",
            "accuracy train:  0.9755329255487591\n",
            "accuracy test:  0.9596959695969597\n",
            "epoch:  14\n",
            "accuracy train:  0.976832947215787\n",
            "accuracy test:  0.9606960696069607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl9HyBKf_EKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}