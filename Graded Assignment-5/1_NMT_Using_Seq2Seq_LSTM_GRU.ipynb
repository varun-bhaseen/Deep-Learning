{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1. NMT_Using_Seq2Seq_LSTM_GRU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# NMT with Seq2Seq, LSTM, and GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLsiwGZEpXaX",
        "colab_type": "text"
      },
      "source": [
        " ### References:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention \n",
        "\n",
        "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html \n",
        "\n",
        "https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnxXKDjq3jEL",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "import numpy as np\n",
        "import unicodedata, re,os, io, time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## Download  the dataset\n",
        "\n",
        "Use language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y87-Pn39qLL7",
        "colab_type": "text"
      },
      "source": [
        "### Download the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRVATYOgJs1b",
        "outputId": "9f87b0e9-4d03-4417-e591-d0681745b3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "path = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "\n",
        "file_zip = keras.utils.get_file('spa-eng.zip', origin=path, extract=True)\n",
        "\n",
        "file_path = os.path.dirname(file_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMTbPUzHqEBI",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprcocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-saqy9z9oPYY",
        "colab_type": "text"
      },
      "source": [
        "#### Converts the unicode file to ascii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rd0jw-eC3jEh",
        "colab": {}
      },
      "source": [
        "def file_to_ascii(u):\n",
        "  return ''.join(f for f in unicodedata.normalize('NFD', u)\n",
        "      if unicodedata.category(c) != 'Mn')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owc8IKmyoNwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "  w = file_to_ascii(w.lower().strip())\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opI2GzOt479E",
        "outputId": "f1b7ef35-3b43-4f61-85cd-4ac32d8e24ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#test\n",
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHn4Dct23jEm",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTbSbBz55QtF",
        "outputId": "ba92bfe8-99ce-4e48-9c15-9ed8a18c5aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "en, sp = create_dataset(file_path, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIOn8RCNDJXG",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAY9k49G3jE_",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster (optional)\n",
        "\n",
        "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnxC7q-j3jFD",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(file_path, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4QILQkOs3jFG",
        "outputId": "299991ce-ed73-42c8-d6c1-08672cc4d29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = tts(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJPmLZGMeD5q",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXukARTDd7MT",
        "outputId": "a992c9ce-f24e-4c53-9cdb-fb12080f1451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "6 ----> ¿\n",
            "38 ----> puedo\n",
            "1383 ----> quedarme\n",
            "44 ----> con\n",
            "30 ----> esto\n",
            "5 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "25 ----> can\n",
            "4 ----> i\n",
            "111 ----> keep\n",
            "19 ----> this\n",
            "7 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqHsArVZ3jFS",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHBoXsCCKpKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qc6-NK1GtWQt",
        "outputId": "7e254b1a-237d-4d2c-b9c3-62b3633f58ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## Write the encoder and decoder model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZ2rI24i3jFg",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60gSVh05Jl6l",
        "outputId": "03e75526-ae41-4dcf-eca4-6ada57ba66cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umohpBN2OM94",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k534zTHiDjQU",
        "outputId": "24558282-369c-4be9-cdfd-893cfdf23a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJ_B3mhW3jFk",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5UY8wko3jFp",
        "outputId": "952450c4-16e1-4288-a472-4c30cfe8452c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmTHr5iV3jFr",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zj8bXQTgNwrF",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hpObfY22IddU"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sC9ArXSsVfqn",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddefjBMa3jF0",
        "outputId": "ee1f6f3b-1e4b-4a18-fa27-6de47c53454c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "# EPOCHS = 1\n",
        "# EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.8202\n",
            "Epoch 1 Batch 100 Loss 2.2124\n",
            "Epoch 1 Batch 200 Loss 1.8868\n",
            "Epoch 1 Batch 300 Loss 1.6880\n",
            "Epoch 1 Loss 2.0270\n",
            "Time taken for 1 epoch 60.84443116188049 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4676\n",
            "Epoch 2 Batch 100 Loss 1.4601\n",
            "Epoch 2 Batch 200 Loss 1.3492\n",
            "Epoch 2 Batch 300 Loss 1.3830\n",
            "Epoch 2 Loss 1.3669\n",
            "Time taken for 1 epoch 60.92120885848999 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1361\n",
            "Epoch 3 Batch 100 Loss 0.9383\n",
            "Epoch 3 Batch 200 Loss 1.0007\n",
            "Epoch 3 Batch 300 Loss 0.8994\n",
            "Epoch 3 Loss 0.9343\n",
            "Time taken for 1 epoch 61.91336011886597 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6544\n",
            "Epoch 4 Batch 100 Loss 0.6933\n",
            "Epoch 4 Batch 200 Loss 0.5853\n",
            "Epoch 4 Batch 300 Loss 0.5710\n",
            "Epoch 4 Loss 0.6265\n",
            "Time taken for 1 epoch 61.76334095001221 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4667\n",
            "Epoch 5 Batch 100 Loss 0.3806\n",
            "Epoch 5 Batch 200 Loss 0.3524\n",
            "Epoch 5 Batch 300 Loss 0.4014\n",
            "Epoch 5 Loss 0.4251\n",
            "Time taken for 1 epoch 61.30935740470886 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2899\n",
            "Epoch 6 Batch 100 Loss 0.2916\n",
            "Epoch 6 Batch 200 Loss 0.2684\n",
            "Epoch 6 Batch 300 Loss 0.2637\n",
            "Epoch 6 Loss 0.2966\n",
            "Time taken for 1 epoch 62.15949535369873 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2407\n",
            "Epoch 7 Batch 100 Loss 0.1677\n",
            "Epoch 7 Batch 200 Loss 0.2338\n",
            "Epoch 7 Batch 300 Loss 0.1864\n",
            "Epoch 7 Loss 0.2127\n",
            "Time taken for 1 epoch 61.599010944366455 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1458\n",
            "Epoch 8 Batch 100 Loss 0.1550\n",
            "Epoch 8 Batch 200 Loss 0.1679\n",
            "Epoch 8 Batch 300 Loss 0.2316\n",
            "Epoch 8 Loss 0.1614\n",
            "Time taken for 1 epoch 62.34117794036865 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1100\n",
            "Epoch 9 Batch 100 Loss 0.1157\n",
            "Epoch 9 Batch 200 Loss 0.1040\n",
            "Epoch 9 Batch 300 Loss 0.1134\n",
            "Epoch 9 Loss 0.1238\n",
            "Time taken for 1 epoch 61.640366554260254 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0811\n",
            "Epoch 10 Batch 100 Loss 0.1021\n",
            "Epoch 10 Batch 200 Loss 0.1170\n",
            "Epoch 10 Batch 300 Loss 0.0795\n",
            "Epoch 10 Loss 0.0997\n",
            "Time taken for 1 epoch 61.72351861000061 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbQpyYs13jF_",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5hQWlbN3jGF",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sl9zUHzg3jGI",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJpT9D5_OgP6",
        "outputId": "d25a40f9-4dd2-4b5a-afa4-e975eeb9a22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9dbde11eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3LLCx3ZE0Ls",
        "outputId": "736b6a2b-0506-4322-c60a-2309ce00e2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DUQVLVqUE1YW",
        "outputId": "782c95d5-6b7e-4737-986a-7df1df201f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: try to figure it out . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cz_baTULCCE",
        "colab_type": "text"
      },
      "source": [
        "This classification shows a wrong output. According to words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMFutL_oLGy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}